{"cells":[{"cell_type":"markdown","metadata":{"id":"ACdIOynx14jD"},"source":["#Data Preparation\n","This notebook includes the necessary code to:\n","*   Import and preprocess the existing tabular dataset\n","*   Make http requests to each recall report to pull all raw html data\n","*   Process all raw html data into raw text data\n","*   Parse text data and extract meaningful phrases to create textual dataset\n","*   Save all data and objects necessary to reproduce results again more efficiently\n","*   Augment existing data and textual data into dataset for analysis\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671832531746,"user":{"displayName":"Nathan Ma","userId":"17789873597166282347"},"user_tz":480},"id":"k3rAHMPn_q5Y"},"outputs":[],"source":["import warnings\n","warnings.simplefilter(action='ignore')\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from google.colab import drive\n","import requests\n","from bs4 import BeautifulSoup as bs\n","import pickle\n","import sys"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32513,"status":"ok","timestamp":1671832569403,"user":{"displayName":"Nathan Ma","userId":"17789873597166282347"},"user_tz":480},"id":"xDIXb7cbAWr0","outputId":"8d4b16e9-4ec7-41bb-feee-1d146551e085"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount(\"/content/drive\") #mount google drive to load data\n","recalls = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/recalls.csv\") #load data from csv to dataframe\n","#can similarly load data from local csv file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-lSnZCAAcX1"},"outputs":[],"source":["#recalls.columns #columns of raw imported data"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8rha5m6-m3eM","executionInfo":{"status":"ok","timestamp":1671832571331,"user_tz":480,"elapsed":302,"user":{"displayName":"Nathan Ma","userId":"17789873597166282347"}}},"outputs":[],"source":["#convert dates to datetime\n","recalls[\"start_date\"] = pd.to_datetime(recalls[\"start_date\"])\n","recalls[\"end_date\"] = pd.to_datetime(recalls[\"end_date\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1DNsE-coaev"},"outputs":[],"source":["#count per year\n","#start_groups = recalls[\"start_date\"].groupby(recalls.start_date.dt.year).value_counts().sum(level=0)\n","\n","#start_groups.plot.line(ylabel=\"count\", xlabel=\"start date year\", rot=\"45\");\n","#[(d, start_groups[d]) for d in start_groups.index]\n","#np.mean(start_groups)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31S1tbeppjzl"},"outputs":[],"source":["#CELL ONLY RUN ONCE FIRST TIME \n","\n","#make requests and save data of request reponses for each recall report\n","\n","recall_requests = []\n","\n","#do not use ipv6, lead to faster request time\n","requests.packages.urllib3.util.connection.HAS_IPV6 = False\n","#start session to make many consequtive requests\n","session = requests.Session()\n","\n","#make requests to gather text data from each recall report url\n","for i, url in enumerate(recalls[\"url\"]):\n","  res = session.get(url)\n","  recall_requests.append(res)\n","  \n","  #print(i)\n","\n","#save the list of request response objects as .dat file to load in later\n","#so do not need to wait hours to make requests each time\n","with open(\"/content/drive/MyDrive/Colab Notebooks/recall_requests.dat\", \"wb\") as f:\n","        pickle.dump(recall_requests, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abAxrQ8WvjJ-"},"outputs":[],"source":["#USE THIS AFTER REQUESTS ARE MADE\n","\n","#load the saved request response objects\n","loaded_requests = []\n","try:\n","  #can also use local file path\n","  with open(\"/content/drive/MyDrive/Colab Notebooks/recall_requests.dat\", \"rb\") as f:\n","      loaded_requests = pickle.load(f)\n","except:\n","    print(\"unable to load requests data\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":179,"status":"ok","timestamp":1671687176583,"user":{"displayName":"Nathan Ma","userId":"17789873597166282347"},"user_tz":480},"id":"ArqfKqGesh5O","outputId":"f63e61fa-2c4b-4ffe-9732-b72def9a3eee"},"outputs":[{"data":{"text/plain":["1338"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["len(loaded_requests) #check length of loaded reqeusts is 1338, equal to number of recalls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-e3lXhCruFOl"},"outputs":[],"source":["#CELL ONLY RUN ONCE FIRST TIME \n","\n","#parse the title of each recall to extract text data\n","locations, products, reasons = [], [], []\n","\n","for req in loaded_requests:\n","  soup = bs(req.text, \"html.parser\")\n","  #print(soup.title.text)\n","  #convert to all lower case and split\n","  title_tokens = str(soup.title.text.lower()).split()\n","\n","  #some titles have no useful information\n","  if title_tokens[:3] == [\"recall\", \"notification\", \"report\"]:\n","    locations.append(\"\")\n","    products.append(\"\")\n","    reasons.append(\"\")\n","  else:\n","    location, product, reason = \"\", \"\", \"\"\n","\n","    #get location or state data about firm if available\n","    try:\n","      location = \" \".join(title_tokens[:title_tokens.index(\"firm\")])\n","    except:\n","      pass \n","    locations.append(location)\n","\n","    #get information about the specific product recalled if available\n","    try:\n","      product = \" \".join(title_tokens[title_tokens.index(\"recalls\")+1: title_tokens.index(\"due\")])\n","    except:\n","      try:\n","        product = \" \".join(title_tokens[title_tokens.index(\"recalls\")+1: title_tokens.index(\"that\")])\n","      except:\n","        try:\n","          product = \" \".join(title_tokens[title_tokens.index(\"recalls\")+1: title_tokens.index(\"products\")+1])\n","        except:\n","          try:\n","            product = \" \".join(title_tokens[title_tokens.index(\"for\")+1: title_tokens.index(\"products\")+1])\n","          except:\n","            try:\n","              product = \" \".join(title_tokens[title_tokens.index(\"for\")+1: title_tokens.index(\"due\")])\n","            except:\n","              pass\n","    products.append(product)\n","      \n","    #get specific recall reason data if available\n","    try:\n","      reason = \" \".join(title_tokens[title_tokens.index(\"to\")+1: title_tokens.index(\"|\")])\n","    except:\n","      try:\n","        reason = \" \".join(title_tokens[title_tokens.index(\"that\")+1: title_tokens.index(\"|\")])\n","      except:\n","        try:\n","          reason = \" \".join(title_tokens[title_tokens.index(\"products\")+1: title_tokens.index(\"|\")])\n","        except:\n","          pass\n","    reasons.append(reason)\n","\n","  #print(location,\";\", product, \";\", reason)\n","\n","\n","#save parsed text data, parsing and text data gathering only needs to be run once\n","#save each list of text data as .dat file to be loaded and used later\n","#can also save as .csv to read \n","with open(\"/content/drive/MyDrive/Colab Notebooks/locations.dat\", \"wb\") as f:\n","  pickle.dump(locations, f)\n","\n","with open(\"/content/drive/MyDrive/Colab Notebooks/products.dat\", \"wb\") as f:\n","  pickle.dump(products, f)\n","\n","with open(\"/content/drive/MyDrive/Colab Notebooks/reasons.dat\", \"wb\") as f:\n","  pickle.dump(reasons, f)\n","\n","with open(\"/content/drive/MyDrive/Colab Notebooks/locations.csv\", \"w\") as f:\n","  for item in locations:\n","    f.write(item + \",\")\n","\n","with open(\"/content/drive/MyDrive/Colab Notebooks/products.csv\", \"w\") as f:\n","  for item in products:\n","    f.write(item + \",\")\n","\n","with open(\"/content/drive/MyDrive/Colab Notebooks/reasons.csv\", \"w\") as f:\n","  for item in reasons:\n","    f.write(item + \",\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAu5GIcpV2QJ"},"outputs":[],"source":["#CELL ONLY RUN ONCE FIRST TIME \n","\n","with open(\"/content/drive/MyDrive/Colab Notebooks/raw_text.txt\", \"w\") as f:\n","  for req in loaded_requests:\n","    f.write(req.text + \"\\n\")\n","#save raw text to txt file"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2705,"status":"ok","timestamp":1671832603555,"user":{"displayName":"Nathan Ma","userId":"17789873597166282347"},"user_tz":480},"id":"qWzqWePAQWdb","outputId":"861bd0bd-cd9b-438d-bc65-a569b15b4209"},"outputs":[{"output_type":"stream","name":"stdout","text":["1338 1338 1338\n"]}],"source":["locations, products, reasons = [], [], []\n","#load parsed text data from saved files\n","try:\n","  with open(\"/content/drive/MyDrive/Colab Notebooks/locations.dat\", \"rb\") as f:\n","    locations = pickle.load(f)\n","except:\n","  print(\"unable to load locations data\")\n","\n","try:\n","  with open(\"/content/drive/MyDrive/Colab Notebooks/products.dat\", \"rb\") as f:\n","    products = pickle.load(f)\n","except:\n","  print(\"unable to load products data\")\n","\n","try:\n","  with open(\"/content/drive/MyDrive/Colab Notebooks/reasons.dat\", \"rb\") as f:\n","    reasons = pickle.load(f)\n","except:\n","  print(\"unable to load reasons data\")\n","\n","#make sure each one is correct length loaded\n","print(len(locations), len(products), len(reasons))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6ocShYSMOhF1","executionInfo":{"status":"ok","timestamp":1671832617752,"user_tz":480,"elapsed":1021,"user":{"displayName":"Nathan Ma","userId":"17789873597166282347"}}},"outputs":[],"source":["#augment generated text data with existing data\n","\n","products_df = pd.DataFrame(products)\n","locations_df = pd.DataFrame(locations)\n","reasons_df = pd.DataFrame(reasons)\n","\n","augmented_df = pd.concat([recalls[[\"start_date\", \"end_date\", \"risk_level\", \"quantity_recovered\", \"url\", \"states\"]], products_df, reasons_df], axis=1)\n","\n","#save as csv to use in analysis\n","augmented_df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/augmented_dataset.csv\")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMM5TSS7bmbaSisTdxWKe3B"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}